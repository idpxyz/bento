# ç¼“å­˜å®ç°è¯„ä¼°æŠ¥å‘Š

## ğŸ“Š **å½“å‰å®ç°æ€»ç»“**

### âœ… **å·²å®Œæˆçš„åŠŸèƒ½**

1. **æ ¸å¿ƒç¼“å­˜æœºåˆ¶**
   - âœ… æ‰©å±• OperationTypeï¼ˆ7ä¸ªæ–°ç±»å‹ï¼‰
   - âœ… å¢å¼º CacheInterceptorï¼ˆæ™ºèƒ½ç¼“å­˜é”®ã€TTLé…ç½®ï¼‰
   - âœ… é›†æˆ Repository Mixinsï¼ˆ12ä¸ªæ–¹æ³•ï¼‰
   - âœ… è‡ªåŠ¨ç¼“å­˜å¤±æ•ˆï¼ˆå†™æ“ä½œè§¦å‘ï¼‰
   - âœ… è‡ªåŠ¨è·¨å®ä½“ç¼“å­˜å¤±æ•ˆï¼ˆé…ç½®åŒ–ï¼‰

2. **æµ‹è¯•è¦†ç›–**
   - âœ… 49ä¸ªæµ‹è¯•ç”¨ä¾‹ï¼Œ100%é€šè¿‡
   - âœ… å•å…ƒæµ‹è¯• + é›†æˆæµ‹è¯•
   - âœ… ç¼“å­˜å‘½ä¸­/å¤±æ•ˆéªŒè¯

3. **æ–‡æ¡£å®Œæ•´æ€§**
   - âœ… 4ä»½è¯¦ç»†æ–‡æ¡£
   - âœ… é…ç½®ç¤ºä¾‹
   - âœ… ä½¿ç”¨æŒ‡å—

---

## âš ï¸ **æ½œåœ¨é—®é¢˜**

### 1. **ç¼“å­˜å‡»ç©¿é£é™©** ğŸ”´ é«˜ä¼˜å…ˆçº§

**é—®é¢˜æè¿°ï¼š**
```python
# å½“å‰å®ç°
async def sum_field_po(self, field: str, spec: Any | None = None):
    # 1. æ£€æŸ¥ç¼“å­˜
    cached = await self._interceptor_chain.execute_before(context)
    if cached is not None:
        return cached

    # 2. ç¼“å­˜æœªå‘½ä¸­ - æŸ¥è¯¢æ•°æ®åº“
    result = await self._session.execute(stmt)

    # 3. ç¼“å­˜ç»“æœ
    await self._interceptor_chain.process_result(context, result_value)
```

**é£é™©ï¼š**
é«˜å¹¶å‘åœºæ™¯ä¸‹ï¼Œçƒ­ç‚¹æ•°æ®è¿‡æœŸæ—¶ï¼š
```python
# æ—¶é—´ç‚¹ T0ï¼šç¼“å­˜è¿‡æœŸ
# æ—¶é—´ç‚¹ T1ï¼š1000ä¸ªå¹¶å‘è¯·æ±‚åŒæ—¶åˆ°è¾¾

Request 1: æ£€æŸ¥ç¼“å­˜ â†’ æœªå‘½ä¸­ â†’ æŸ¥è¯¢æ•°æ®åº“
Request 2: æ£€æŸ¥ç¼“å­˜ â†’ æœªå‘½ä¸­ â†’ æŸ¥è¯¢æ•°æ®åº“
Request 3: æ£€æŸ¥ç¼“å­˜ â†’ æœªå‘½ä¸­ â†’ æŸ¥è¯¢æ•°æ®åº“
...
Request 1000: æ£€æŸ¥ç¼“å­˜ â†’ æœªå‘½ä¸­ â†’ æŸ¥è¯¢æ•°æ®åº“

# âŒ ç»“æœï¼š1000ä¸ªè¯·æ±‚åŒæ—¶æ‰“åˆ°æ•°æ®åº“ï¼
```

**å½±å“ï¼š**
- æ•°æ®åº“ç¬æ—¶å‹åŠ›æ¿€å¢
- å¯èƒ½å¯¼è‡´æ•°æ®åº“è¿æ¥æ± è€—å°½
- ä¸¥é‡æ—¶å¯èƒ½é€ æˆé›ªå´©

**å»ºè®®è§£å†³æ–¹æ¡ˆï¼š**
```python
# æ–¹æ¡ˆ 1: Singleflight/Mutex æ¨¡å¼
class SingleflightGroup:
    """ç¡®ä¿åŒä¸€æ—¶åˆ»åªæœ‰ä¸€ä¸ªè¯·æ±‚æŸ¥è¯¢æ•°æ®åº“"""

    async def do(self, key: str, fn: Callable):
        async with self._lock:
            if key in self._calls:
                # ç­‰å¾…å·²æœ‰çš„è°ƒç”¨
                return await self._calls[key]
            else:
                # åˆ›å»ºæ–°çš„è°ƒç”¨
                future = asyncio.Future()
                self._calls[key] = future
                try:
                    result = await fn()
                    future.set_result(result)
                    return result
                finally:
                    self._calls.pop(key, None)

# ä½¿ç”¨
group = SingleflightGroup()
result = await group.do(cache_key, lambda: query_database())
```

**ä¼˜å…ˆçº§ï¼š** ğŸ”´ é«˜ï¼ˆç”Ÿäº§ç¯å¢ƒå¿…é¡»è§£å†³ï¼‰

---

### 2. **ç¼“å­˜ç©¿é€é£é™©** ğŸŸ¡ ä¸­ä¼˜å…ˆçº§

**é—®é¢˜æè¿°ï¼š**
```python
# å½“å‰å®ç°å¯¹ None ç»“æœä¸ç¼“å­˜
if result is not None:
    await self._cache.set(key, result, ttl=ttl)
```

**é£é™©ï¼š**
```python
# æ”»å‡»è€…æŸ¥è¯¢ä¸å­˜åœ¨çš„æ•°æ®
for i in range(10000):
    await repo.get(ID(f"non_existent_{i}"))
    # æ¯æ¬¡éƒ½æŸ¥è¯¢æ•°æ®åº“ï¼Œå› ä¸º None ä¸ä¼šè¢«ç¼“å­˜
```

**å½±å“ï¼š**
- æ¶æ„è¯·æ±‚å¯ä»¥ç»•è¿‡ç¼“å­˜
- æ•°æ®åº“æ‰¿å—å¤§é‡æ— æ•ˆæŸ¥è¯¢

**å»ºè®®è§£å†³æ–¹æ¡ˆï¼š**
```python
# æ–¹æ¡ˆ 1: ç¼“å­˜ç©ºç»“æœï¼ˆæ¨èï¼‰
CACHE_NULL_OBJECT = object()  # ç‰¹æ®Šæ ‡è®°

async def process_result(self, context, result, next_interceptor):
    if self._is_read(context.operation):
        key = self._get_cache_key(context)
        if key:
            # âœ… ç¼“å­˜ç©ºç»“æœï¼Œä½¿ç”¨çŸ­TTL
            cache_value = result if result is not None else CACHE_NULL_OBJECT
            ttl = 60 if result is not None else 10  # ç©ºç»“æœçŸ­æœŸç¼“å­˜
            await self._cache.set(key, cache_value, ttl=ttl)

async def execute_before(self, context):
    cached = await self._cache.get(key)
    if cached is CACHE_NULL_OBJECT:
        return None  # è¿”å› Noneï¼Œä½†é¿å…äº†æ•°æ®åº“æŸ¥è¯¢
    return cached

# æ–¹æ¡ˆ 2: å¸ƒéš†è¿‡æ»¤å™¨ï¼ˆé«˜çº§ï¼‰
class BloomFilter:
    """åˆ¤æ–­æ•°æ®æ˜¯å¦å­˜åœ¨"""
    def add(self, key): ...
    def contains(self, key) -> bool: ...

# åœ¨æŸ¥è¯¢å‰å…ˆæ£€æŸ¥
if not bloom_filter.contains(entity_id):
    return None  # ç›´æ¥è¿”å›ï¼Œä¸æŸ¥æ•°æ®åº“
```

**ä¼˜å…ˆçº§ï¼š** ğŸŸ¡ ä¸­ï¼ˆæ ¹æ®ä¸šåŠ¡åœºæ™¯å†³å®šï¼‰

---

### 3. **ç¼“å­˜é›ªå´©é£é™©** ğŸŸ¡ ä¸­ä¼˜å…ˆçº§

**é—®é¢˜æè¿°ï¼š**
```python
# æ‰€æœ‰ç¼“å­˜ä½¿ç”¨ç›¸åŒçš„ TTL
ttl_config = {
    OperationType.AGGREGATE: 600,  # æ‰€æœ‰èšåˆæŸ¥è¯¢éƒ½æ˜¯10åˆ†é’Ÿ
}
```

**é£é™©ï¼š**
```python
# å¦‚æœå¤§é‡ç¼“å­˜åŒæ—¶åˆ›å»ºï¼ˆå¦‚ç³»ç»Ÿé‡å¯åï¼‰
# å®ƒä»¬ä¼šåœ¨åŒä¸€æ—¶é—´è¿‡æœŸ
T0: åˆ›å»º1000ä¸ªç¼“å­˜ï¼ŒTTL=600ç§’
T600: 1000ä¸ªç¼“å­˜åŒæ—¶è¿‡æœŸ
T600+1: 1000ä¸ªè¯·æ±‚åŒæ—¶æ‰“åˆ°æ•°æ®åº“
```

**å½±å“ï¼š**
- å¤§é‡ç¼“å­˜åŒæ—¶å¤±æ•ˆ
- æ•°æ®åº“ç¬æ—¶å‹åŠ›æ¿€å¢

**å»ºè®®è§£å†³æ–¹æ¡ˆï¼š**
```python
# æ–¹æ¡ˆ 1: TTL åŠ éšæœºæŠ–åŠ¨
import random

async def process_result(self, context, result, next_interceptor):
    base_ttl = self._get_ttl(context.operation)
    # âœ… æ·»åŠ  Â±10% çš„éšæœºæŠ–åŠ¨
    jitter = random.uniform(0.9, 1.1)
    actual_ttl = int(base_ttl * jitter)
    await self._cache.set(key, result, ttl=actual_ttl)

# æ–¹æ¡ˆ 2: äºŒçº§ç¼“å­˜ + æå‰åˆ·æ–°
# åœ¨ç¼“å­˜å³å°†è¿‡æœŸå‰ï¼ˆå¦‚å‰©ä½™10%æ—¶é—´ï¼‰æå‰åˆ·æ–°
if ttl_remaining < base_ttl * 0.1:
    asyncio.create_task(refresh_cache_async())
```

**ä¼˜å…ˆçº§ï¼š** ğŸŸ¡ ä¸­ï¼ˆç”Ÿäº§ç¯å¢ƒå»ºè®®å®æ–½ï¼‰

---

### 4. **å†…å­˜ç®¡ç†é—®é¢˜** ğŸŸ¡ ä¸­ä¼˜å…ˆçº§

**é—®é¢˜æè¿°ï¼š**
```python
# å½“å‰æ²¡æœ‰å¯¹ç¼“å­˜å¤§å°çš„é™åˆ¶
# å¯èƒ½å¯¼è‡´å†…å­˜æ— é™å¢é•¿
```

**é£é™©ï¼š**
```python
# å¤§é‡ä¸åŒçš„æŸ¥è¯¢æ¡ä»¶
for i in range(1000000):
    await repo.find_paginated_po(page=i, page_size=20)
    # âœ… æ¯ä¸ªé¡µç éƒ½ä¼šç¼“å­˜
    # âŒ å¯èƒ½ç¼“å­˜æ•°ç™¾ä¸‡æ¡æ•°æ®
```

**å½±å“ï¼š**
- å†…å­˜å ç”¨æ— é™å¢é•¿
- å¯èƒ½å¯¼è‡´ OOM

**å»ºè®®è§£å†³æ–¹æ¡ˆï¼š**
```python
# æ–¹æ¡ˆ 1: è®¾ç½®æœ€å¤§ç¼“å­˜å¤§å°
cache_config = CacheConfig(
    backend=CacheBackend.MEMORY,
    max_size=10000,  # âœ… æœ€å¤š10000ä¸ªç¼“å­˜é¡¹
    eviction_policy="LRU"  # âœ… LRU é©±é€ç­–ç•¥
)

# æ–¹æ¡ˆ 2: ç›‘æ§ç¼“å­˜å¤§å°
class MonitoredCache:
    async def set(self, key, value, ttl):
        if len(self._cache) > self._max_size:
            # é©±é€æœ€å°‘ä½¿ç”¨çš„é¡¹
            self._evict_lru()
        await super().set(key, value, ttl)
```

**ä¼˜å…ˆçº§ï¼š** ğŸŸ¡ ä¸­ï¼ˆç”Ÿäº§ç¯å¢ƒå¿…é¡»è®¾ç½®ï¼‰

---

### 5. **å¹¶å‘å®‰å…¨é—®é¢˜** ğŸŸ¢ ä½ä¼˜å…ˆçº§

**é—®é¢˜æè¿°ï¼š**
```python
# å½“å‰çš„ç¼“å­˜å¤±æ•ˆæ˜¯å¼‚æ­¥çš„
await self._cache.delete_pattern(f"{et}:agg:*")

# å¯èƒ½å­˜åœ¨ç«æ€æ¡ä»¶
```

**é£é™©ï¼š**
```python
# çº¿ç¨‹ 1
cached = await cache.get(key)  # è·å–åˆ°æ—§å€¼
await process(cached)

# çº¿ç¨‹ 2ï¼ˆåŒæ—¶å‘ç”Ÿï¼‰
await cache.delete(key)  # åˆ é™¤ç¼“å­˜
await cache.set(key, new_value)  # è®¾ç½®æ–°å€¼

# çº¿ç¨‹ 1 ç»§ç»­
await cache.set(key, old_value)  # âŒ è¦†ç›–äº†æ–°å€¼ï¼
```

**å½±å“ï¼š**
- å¯èƒ½å‡ºç°æ•°æ®ä¸ä¸€è‡´

**å»ºè®®è§£å†³æ–¹æ¡ˆï¼š**
```python
# æ–¹æ¡ˆ 1: ä½¿ç”¨ç‰ˆæœ¬å·
class VersionedCache:
    async def set_with_version(self, key, value, version, ttl):
        current_version = await self.get_version(key)
        if current_version is None or version > current_version:
            await self._cache.set(key, (version, value), ttl)
        # å¦åˆ™æ‹’ç»æ›´æ–°

# æ–¹æ¡ˆ 2: ä½¿ç”¨åˆ†å¸ƒå¼é”
async with RedisLock(f"lock:{key}"):
    value = await cache.get(key)
    # å¤„ç†...
    await cache.set(key, new_value)
```

**ä¼˜å…ˆçº§ï¼š** ğŸŸ¢ ä½ï¼ˆå½“å‰å®ç°åŸºæœ¬å®‰å…¨ï¼‰

---

### 6. **å¯è§‚æµ‹æ€§ä¸è¶³** ğŸŸ¡ ä¸­ä¼˜å…ˆçº§

**é—®é¢˜æè¿°ï¼š**
å½“å‰ç¼ºå°‘ç¼“å­˜ç›‘æ§å’Œè¯Šæ–­èƒ½åŠ›ã€‚

**ç¼ºå¤±çš„åŠŸèƒ½ï¼š**
```python
# âŒ æ²¡æœ‰ç¼“å­˜å‘½ä¸­ç‡ç»Ÿè®¡
# âŒ æ²¡æœ‰ç¼“å­˜å¤±æ•ˆæ¬¡æ•°ç›‘æ§
# âŒ æ²¡æœ‰ç¼“å­˜å¤§å°ç›‘æ§
# âŒ æ²¡æœ‰æ…¢æŸ¥è¯¢æ—¥å¿—
```

**å½±å“ï¼š**
- æ— æ³•è¯„ä¼°ç¼“å­˜æ•ˆæœ
- éš¾ä»¥å‘ç°é—®é¢˜
- æ— æ³•ä¼˜åŒ–ç¼“å­˜ç­–ç•¥

**å»ºè®®è§£å†³æ–¹æ¡ˆï¼š**
```python
# æ–¹æ¡ˆ 1: æ·»åŠ æŒ‡æ ‡æ”¶é›†
class MetricsCache:
    def __init__(self, cache, metrics):
        self._cache = cache
        self._metrics = metrics

    async def get(self, key):
        result = await self._cache.get(key)
        if result is not None:
            self._metrics.increment("cache.hit")
        else:
            self._metrics.increment("cache.miss")
        return result

    async def set(self, key, value, ttl):
        await self._cache.set(key, value, ttl)
        self._metrics.increment("cache.set")
        self._metrics.gauge("cache.size", len(self._cache))

# æ–¹æ¡ˆ 2: æ·»åŠ æ—¥å¿—
class LoggingCache:
    async def get(self, key):
        start = time.time()
        result = await self._cache.get(key)
        duration = time.time() - start

        logger.info(
            "cache.get",
            key=key,
            hit=result is not None,
            duration=duration
        )
        return result

# æ–¹æ¡ˆ 3: æ·»åŠ å¥åº·æ£€æŸ¥ç«¯ç‚¹
@app.get("/health/cache")
async def cache_health():
    return {
        "size": cache.size(),
        "hit_rate": cache.hit_rate(),
        "memory_usage": cache.memory_usage(),
        "top_keys": cache.top_keys(10)
    }
```

**ä¼˜å…ˆçº§ï¼š** ğŸŸ¡ ä¸­ï¼ˆç”Ÿäº§ç¯å¢ƒå¼ºçƒˆå»ºè®®ï¼‰

---

### 7. **ç¼“å­˜é”®å†²çªé£é™©** ğŸŸ¢ ä½ä¼˜å…ˆçº§

**é—®é¢˜æè¿°ï¼š**
```python
# å½“å‰çš„ç¼“å­˜é”®ç”Ÿæˆ
key = f"{entity_type}:agg:sum:{field}:{spec_hash}"
```

**é£é™©ï¼š**
```python
# ä¸åŒçš„ specification å¯èƒ½äº§ç”Ÿç›¸åŒçš„ hash
spec1 = ProductSpec().by_category("A")
spec2 = ProductSpec().by_price_range(1, 10)

hash(spec1) == hash(spec2)  # å¯èƒ½ç›¸ç­‰ï¼
```

**å½±å“ï¼š**
- ä¸åŒæŸ¥è¯¢å¯èƒ½å…±äº«ç¼“å­˜
- è¿”å›é”™è¯¯çš„ç»“æœ

**å»ºè®®è§£å†³æ–¹æ¡ˆï¼š**
```python
# æ–¹æ¡ˆ 1: ä½¿ç”¨æ›´å¼ºçš„å“ˆå¸Œç®—æ³•
import hashlib

def _hash_specification(spec):
    if spec is None:
        return "none"

    # åºåˆ—åŒ– spec çš„æ‰€æœ‰å±æ€§
    spec_str = json.dumps(spec.to_dict(), sort_keys=True)
    # ä½¿ç”¨ SHA256
    return hashlib.sha256(spec_str.encode()).hexdigest()[:16]

# æ–¹æ¡ˆ 2: æ·»åŠ æ›´å¤šä¸Šä¸‹æ–‡
key = f"{entity_type}:agg:sum:{field}:{spec_hash}:{actor}:{tenant_id}"
```

**ä¼˜å…ˆçº§ï¼š** ğŸŸ¢ ä½ï¼ˆå½“å‰å®ç°åŸºæœ¬å®‰å…¨ï¼‰

---

### 8. **è·¨å®ä½“å¤±æ•ˆçš„å®Œæ•´æ€§** ğŸŸ¡ ä¸­ä¼˜å…ˆçº§

**é—®é¢˜æè¿°ï¼š**
```python
# å½“å‰éœ€è¦æ‰‹åŠ¨é…ç½®è·¨å®ä½“å…³è”
config.add_relation(
    EntityRelation(source_entity="Order", related_entities=["Customer"])
)
```

**é£é™©ï¼š**
```python
# å¼€å‘è€…å¯èƒ½å¿˜è®°é…ç½®æŸäº›å…³è”
# ä¾‹å¦‚ï¼šOrder ä¹Ÿå½±å“ Product çš„åº“å­˜ï¼Œä½†å¿˜è®°é…ç½®

await order_repo.save(order)
# âœ… Customer ç¼“å­˜è‡ªåŠ¨å¤±æ•ˆ
# âŒ Product ç¼“å­˜æ²¡æœ‰å¤±æ•ˆï¼ˆå› ä¸ºæ²¡é…ç½®ï¼‰
```

**å½±å“ï¼š**
- é…ç½®é—æ¼å¯¼è‡´ç¼“å­˜ä¸ä¸€è‡´
- éš¾ä»¥å‘ç°å’Œè°ƒè¯•

**å»ºè®®è§£å†³æ–¹æ¡ˆï¼š**
```python
# æ–¹æ¡ˆ 1: è¿è¡Œæ—¶éªŒè¯
class RelationValidator:
    def validate_relations(self, config):
        """éªŒè¯å…³è”å…³ç³»çš„å®Œæ•´æ€§"""
        # æ£€æŸ¥æ˜¯å¦æœ‰æœªé…ç½®çš„å®ä½“
        # æ£€æŸ¥æ˜¯å¦æœ‰å¾ªç¯ä¾èµ–
        # ç”Ÿæˆè­¦å‘ŠæŠ¥å‘Š

# æ–¹æ¡ˆ 2: è‡ªåŠ¨å‘ç°å…³è”ï¼ˆé«˜çº§ï¼‰
class AutoDiscoveryRelations:
    def discover_relations(self, aggregate_root):
        """é€šè¿‡åˆ†æèšåˆæ ¹çš„å±æ€§è‡ªåŠ¨å‘ç°å…³è”"""
        relations = []
        for field in aggregate_root.__dataclass_fields__:
            if is_entity_reference(field):
                relations.append(field.name)
        return relations

# æ–¹æ¡ˆ 3: æµ‹è¯•è¦†ç›–
def test_all_relations_configured():
    """æµ‹è¯•æ‰€æœ‰å®ä½“å…³è”éƒ½å·²é…ç½®"""
    expected_relations = [
        ("Order", "Customer"),
        ("Order", "Product"),
        ("Review", "Product"),
    ]

    for source, target in expected_relations:
        assert config.has_relation(source, target)
```

**ä¼˜å…ˆçº§ï¼š** ğŸŸ¡ ä¸­ï¼ˆå»ºè®®æ·»åŠ éªŒè¯æœºåˆ¶ï¼‰

---

## ğŸ”§ **éœ€è¦æ”¹è¿›çš„åœ°æ–¹**

### 1. **æ€§èƒ½ä¼˜åŒ–**

#### A. æ‰¹é‡ç¼“å­˜æ“ä½œ
```python
# å½“å‰ï¼šé€ä¸ªè®¾ç½®ç¼“å­˜
for item in items:
    await cache.set(f"key:{item.id}", item)

# âœ… æ”¹è¿›ï¼šæ‰¹é‡è®¾ç½®
await cache.mset({
    f"key:{item.id}": item
    for item in items
})
```

#### B. ç¼“å­˜é¢„çƒ­
```python
# æ·»åŠ ç¼“å­˜é¢„çƒ­åŠŸèƒ½
class CacheWarmer:
    async def warm_up(self):
        """åœ¨åº”ç”¨å¯åŠ¨æ—¶é¢„çƒ­å¸¸ç”¨ç¼“å­˜"""
        # é¢„çƒ­çƒ­ç‚¹æ•°æ®
        await self._warm_top_products()
        await self._warm_categories()
        await self._warm_statistics()
```

#### C. åˆ†å±‚ç¼“å­˜
```python
# L1: æœ¬åœ°å†…å­˜ç¼“å­˜ï¼ˆæå¿«ï¼Œå®¹é‡å°ï¼‰
# L2: Redis ç¼“å­˜ï¼ˆå¿«ï¼Œå®¹é‡å¤§ï¼‰
class TieredCache:
    def __init__(self, l1_cache, l2_cache):
        self._l1 = l1_cache
        self._l2 = l2_cache

    async def get(self, key):
        # å…ˆæŸ¥ L1
        value = await self._l1.get(key)
        if value is not None:
            return value

        # å†æŸ¥ L2
        value = await self._l2.get(key)
        if value is not None:
            # å›å†™åˆ° L1
            await self._l1.set(key, value)

        return value
```

---

### 2. **åŠŸèƒ½å¢å¼º**

#### A. ç¼“å­˜æ ‡ç­¾
```python
# æ”¯æŒæŒ‰æ ‡ç­¾æ‰¹é‡å¤±æ•ˆ
await cache.set("product:123", product, tags=["product", "category:electronics"])
await cache.set("product:456", product2, tags=["product", "category:electronics"])

# å¤±æ•ˆæ‰€æœ‰ç”µå­äº§å“ç¼“å­˜
await cache.delete_by_tag("category:electronics")
```

#### B. ç¼“å­˜ä¾èµ–
```python
# å®šä¹‰ç¼“å­˜ä¾èµ–å…³ç³»
cache_deps = {
    "customer_orders": ["order_*"],
    "product_sales": ["order_items_*"],
}

# å½“ä¾èµ–å˜åŒ–æ—¶è‡ªåŠ¨å¤±æ•ˆ
await cache.delete_with_deps("order_123")
# è‡ªåŠ¨å¤±æ•ˆ: customer_orders, product_sales
```

#### C. ç¼“å­˜åˆ·æ–°ç­–ç•¥
```python
# è‡ªåŠ¨åˆ·æ–°å³å°†è¿‡æœŸçš„ç¼“å­˜
class AutoRefreshCache:
    async def get(self, key):
        value, ttl = await self._cache.get_with_ttl(key)

        # å¦‚æœå‰©ä½™æ—¶é—´ < 10%ï¼Œåå°åˆ·æ–°
        if ttl < self._base_ttl * 0.1:
            asyncio.create_task(self._refresh(key))

        return value
```

---

### 3. **æµ‹è¯•å¢å¼º**

#### A. æ€§èƒ½æµ‹è¯•
```python
@pytest.mark.benchmark
async def test_cache_performance():
    """æµ‹è¯•ç¼“å­˜æ€§èƒ½"""
    # æµ‹è¯•ç¼“å­˜å‘½ä¸­æ€§èƒ½
    start = time.time()
    for _ in range(1000):
        await repo.sum_field("price")
    duration = time.time() - start

    assert duration < 1.0  # 1000æ¬¡æŸ¥è¯¢åº”è¯¥ < 1ç§’
```

#### B. å¹¶å‘æµ‹è¯•
```python
@pytest.mark.asyncio
async def test_cache_under_concurrent_load():
    """æµ‹è¯•å¹¶å‘åœºæ™¯ä¸‹çš„ç¼“å­˜è¡Œä¸º"""
    tasks = [
        repo.sum_field("price")
        for _ in range(100)
    ]
    results = await asyncio.gather(*tasks)

    # æ‰€æœ‰ç»“æœåº”è¯¥ä¸€è‡´
    assert len(set(results)) == 1
```

#### C. ç¼“å­˜å‡»ç©¿æµ‹è¯•
```python
@pytest.mark.asyncio
async def test_cache_breakdown_protection():
    """æµ‹è¯•ç¼“å­˜å‡»ç©¿ä¿æŠ¤"""
    # æ¸…ç©ºç¼“å­˜
    await cache.clear()

    # å‘é€100ä¸ªå¹¶å‘è¯·æ±‚
    with mock.patch("repository.query_db") as mock_query:
        mock_query.return_value = 100

        tasks = [repo.sum_field("price") for _ in range(100)]
        await asyncio.gather(*tasks)

        # âœ… åº”è¯¥åªæŸ¥è¯¢ä¸€æ¬¡æ•°æ®åº“
        assert mock_query.call_count == 1
```

---

### 4. **æ–‡æ¡£å®Œå–„**

#### A. æ·»åŠ æ€§èƒ½æŒ‡å—
```markdown
# ç¼“å­˜æ€§èƒ½æŒ‡å—

## ä½•æ—¶ä½¿ç”¨ç¼“å­˜
- âœ… è¯»å¤šå†™å°‘çš„æ•°æ®
- âœ… è®¡ç®—æˆæœ¬é«˜çš„æŸ¥è¯¢
- âŒ å®æ—¶æ€§è¦æ±‚æé«˜çš„æ•°æ®
- âŒ é«˜é¢‘å˜åŒ–çš„æ•°æ®

## TTL è®¾ç½®å»ºè®®
- ç»Ÿè®¡æ•°æ®: 10-60åˆ†é’Ÿ
- åˆ—è¡¨æŸ¥è¯¢: 5-30åˆ†é’Ÿ
- è¯¦æƒ…æŸ¥è¯¢: 1-10åˆ†é’Ÿ
- æœç´¢ç»“æœ: 1-5åˆ†é’Ÿ
```

#### B. æ·»åŠ æ•…éšœæ’æŸ¥æŒ‡å—
```markdown
# ç¼“å­˜é—®é¢˜æ’æŸ¥

## ç¼“å­˜æœªå‘½ä¸­ç‡é«˜
1. æ£€æŸ¥ TTL æ˜¯å¦è¿‡çŸ­
2. æ£€æŸ¥ç¼“å­˜é”®æ˜¯å¦æ­£ç¡®
3. æ£€æŸ¥æ˜¯å¦æœ‰é¢‘ç¹çš„å†™æ“ä½œ

## ç¼“å­˜æ•°æ®ä¸ä¸€è‡´
1. æ£€æŸ¥ç¼“å­˜å¤±æ•ˆé…ç½®
2. æ£€æŸ¥è·¨å®ä½“å…³è”æ˜¯å¦å®Œæ•´
3. æ£€æŸ¥æ˜¯å¦æœ‰ç»•è¿‡ç¼“å­˜çš„ç›´æ¥æŸ¥è¯¢
```

---

## ğŸ“‹ **ä¼˜å…ˆçº§å»ºè®®**

### ğŸ”´ é«˜ä¼˜å…ˆçº§ï¼ˆç”Ÿäº§å‰å¿…é¡»è§£å†³ï¼‰
1. **ç¼“å­˜å‡»ç©¿ä¿æŠ¤** - å®ç° Singleflight æ¨¡å¼
2. **å†…å­˜é™åˆ¶** - è®¾ç½®æœ€å¤§ç¼“å­˜å¤§å°
3. **å¯è§‚æµ‹æ€§** - æ·»åŠ åŸºæœ¬çš„ç›‘æ§æŒ‡æ ‡

### ğŸŸ¡ ä¸­ä¼˜å…ˆçº§ï¼ˆç”Ÿäº§åå°½å¿«å®æ–½ï¼‰
4. **ç¼“å­˜ç©¿é€ä¿æŠ¤** - ç¼“å­˜ç©ºç»“æœ
5. **ç¼“å­˜é›ªå´©ä¿æŠ¤** - TTL éšæœºæŠ–åŠ¨
6. **è·¨å®ä½“å¤±æ•ˆéªŒè¯** - æ·»åŠ é…ç½®æ£€æŸ¥
7. **æ€§èƒ½ä¼˜åŒ–** - æ‰¹é‡æ“ä½œã€ç¼“å­˜é¢„çƒ­

### ğŸŸ¢ ä½ä¼˜å…ˆçº§ï¼ˆæŒç»­æ”¹è¿›ï¼‰
8. **åŠŸèƒ½å¢å¼º** - æ ‡ç­¾ã€ä¾èµ–ã€è‡ªåŠ¨åˆ·æ–°
9. **æµ‹è¯•å¢å¼º** - æ€§èƒ½æµ‹è¯•ã€å¹¶å‘æµ‹è¯•
10. **æ–‡æ¡£å®Œå–„** - æ€§èƒ½æŒ‡å—ã€æ•…éšœæ’æŸ¥

---

## ğŸ¯ **æ¨èå®æ–½è·¯çº¿å›¾**

### Phase 1: ç”Ÿäº§å°±ç»ªï¼ˆ2-3å¤©ï¼‰
- [ ] å®ç°ç¼“å­˜å‡»ç©¿ä¿æŠ¤
- [ ] è®¾ç½®å†…å­˜é™åˆ¶å’Œ LRU é©±é€
- [ ] æ·»åŠ åŸºæœ¬ç›‘æ§ï¼ˆå‘½ä¸­ç‡ã€å¤§å°ï¼‰
- [ ] æ·»åŠ  TTL éšæœºæŠ–åŠ¨

### Phase 2: ç¨³å®šæ€§æå‡ï¼ˆ1å‘¨ï¼‰
- [ ] å®ç°ç¼“å­˜ç©¿é€ä¿æŠ¤
- [ ] æ·»åŠ å…³è”å…³ç³»éªŒè¯
- [ ] å®Œå–„ç›‘æ§å’Œå‘Šè­¦
- [ ] æ·»åŠ æ€§èƒ½æµ‹è¯•

### Phase 3: ä½“éªŒä¼˜åŒ–ï¼ˆ2å‘¨ï¼‰
- [ ] å®ç°ç¼“å­˜é¢„çƒ­
- [ ] æ·»åŠ ç¼“å­˜æ ‡ç­¾åŠŸèƒ½
- [ ] å®ç°è‡ªåŠ¨åˆ·æ–°
- [ ] å®Œå–„æ–‡æ¡£

---

## âœ… **æ€»ç»“**

### å½“å‰çŠ¶æ€
- âœ… **æ ¸å¿ƒåŠŸèƒ½å®Œæ•´** - åŸºæœ¬çš„ç¼“å­˜å’Œå¤±æ•ˆæœºåˆ¶å·²å®ç°
- âœ… **æµ‹è¯•è¦†ç›–è‰¯å¥½** - 49ä¸ªæµ‹è¯•ç”¨ä¾‹å…¨éƒ¨é€šè¿‡
- âš ï¸ **ç”Ÿäº§å°±ç»ªåº¦** - éœ€è¦è§£å†³ç¼“å­˜å‡»ç©¿ç­‰é—®é¢˜

### ä¸»è¦é£é™©
1. ğŸ”´ ç¼“å­˜å‡»ç©¿ - é«˜å¹¶å‘åœºæ™¯ä¸‹çš„æ•°æ®åº“å‹åŠ›
2. ğŸŸ¡ ç¼“å­˜ç©¿é€ - æ¶æ„è¯·æ±‚ç»•è¿‡ç¼“å­˜
3. ğŸŸ¡ å†…å­˜ç®¡ç† - å¯èƒ½çš„å†…å­˜æ³„æ¼

### å»ºè®®è¡ŒåŠ¨
1. **ç«‹å³å®æ–½** - ç¼“å­˜å‡»ç©¿ä¿æŠ¤å’Œå†…å­˜é™åˆ¶
2. **çŸ­æœŸå®æ–½** - å¯è§‚æµ‹æ€§å’Œç©¿é€ä¿æŠ¤
3. **æŒç»­æ”¹è¿›** - åŠŸèƒ½å¢å¼ºå’Œæ€§èƒ½ä¼˜åŒ–

**æ€»ä½“è¯„ä»·ï¼šå½“å‰å®ç°æ˜¯ä¸€ä¸ªè‰¯å¥½çš„èµ·ç‚¹ï¼Œä½†éœ€è¦é’ˆå¯¹ç”Ÿäº§ç¯å¢ƒè¿›è¡ŒåŠ å›ºã€‚** ğŸ¯
