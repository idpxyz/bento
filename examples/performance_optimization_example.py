"""Performance optimization example for Outbox and MessageBus.

This example demonstrates:
- Performance monitoring setup
- Database optimization strategies
- Connection pool configuration
- Historical data cleanup
- Bottleneck analysis and recommendations
"""

import asyncio
import logging

from sqlalchemy.ext.asyncio import async_sessionmaker, create_async_engine

from bento.config.outbox import OutboxProjectorConfig
from bento.infrastructure.monitoring.performance import (
    PerformanceMonitor,
    cleanup_old_outbox_records
)
from bento.infrastructure.projection.projector import OutboxProjector
from bento.adapters.messaging.inprocess.message_bus import InProcessMessageBus

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


async def performance_optimization_demo():
    """Demonstrate performance optimization features."""

    print("üöÄ Performance Optimization Demo")
    print("=" * 40)

    # 1. Setup optimized database configuration
    print("\nüìä 1. Database Performance Setup")

    # Create engine with optimized configuration
    DATABASE_URL = "sqlite+aiosqlite:///:memory:"  # In production: PostgreSQL

    # For SQLite (demo), use basic configuration
    engine = create_async_engine(
        DATABASE_URL,
        echo=False  # Disable SQL logging in production
    )

    # NOTE: In production with PostgreSQL, use these optimizations:
    # engine = create_async_engine(
    #     "postgresql+asyncpg://user:pass@host:port/db",
    #     pool_size=20,           # Increased connection pool
    #     max_overflow=10,        # Allow overflow connections
    #     pool_pre_ping=True,     # Validate connections
    #     pool_recycle=3600,      # Recycle connections hourly
    #     echo=False
    # )

    session_factory = async_sessionmaker(engine, expire_on_commit=False)
    print("   ‚úÖ Optimized database connection pool configured")

    # 2. Setup performance monitoring
    print("\nüîç 2. Performance Monitoring Setup")

    performance_monitor = PerformanceMonitor(session_factory)
    print("   ‚úÖ Performance monitor initialized")

    # 3. Configure high-performance OutboxProjector
    print("\n‚ö° 3. High-Performance OutboxProjector Configuration")

    # High-throughput configuration
    high_perf_config = OutboxProjectorConfig(
        batch_size=500,                    # Larger batches for throughput
        max_concurrent_projectors=10,      # More concurrent workers
        sleep_busy=0.05,                   # Faster polling when busy
        sleep_idle=0.5,                    # Quicker response to new events
        enable_performance_monitoring=True, # Enable monitoring
        connection_pool_size=30,           # Larger connection pool
        query_timeout_seconds=15,          # Shorter timeout for faster failure
        batch_commit_size=2000             # Larger commit batches
    )

    message_bus = InProcessMessageBus(source="perf-demo")

    projector = OutboxProjector(
        session_factory=session_factory,
        message_bus=message_bus,
        tenant_id="high_perf_tenant",
        config=high_perf_config
    )

    print(f"   ‚úÖ High-performance projector configured:")
    print(f"      - Batch size: {high_perf_config.batch_size}")
    print(f"      - Max concurrent: {high_perf_config.max_concurrent_projectors}")
    print(f"      - Theoretical TPS: {high_perf_config.batch_size / high_perf_config.sleep_busy:.0f}")

    # 4. Real-time performance monitoring
    print("\nüìà 4. Real-time Performance Monitoring")

    try:
        # Get current metrics
        metrics = await performance_monitor.get_metrics()

        print("   Current Performance Metrics:")
        print(f"      - Pending events: {metrics.pending_events}")
        print(f"      - Events/second: {metrics.events_per_second:.2f}")
        print(f"      - Average query time: {metrics.avg_query_time_ms:.2f}ms")
        print(f"      - Connection pool usage: {metrics.active_connections}/{metrics.connection_pool_size}")

        # Analyze for bottlenecks
        analysis = await performance_monitor.analyze_performance_bottlenecks()

        print(f"\\n   Performance Analysis (Severity: {analysis['severity']}):")
        if analysis['bottlenecks']:
            for bottleneck in analysis['bottlenecks']:
                print(f"      ‚ö†Ô∏è  {bottleneck}")
        else:
            print("      ‚úÖ No performance bottlenecks detected")

        if analysis['recommendations']:
            print("\\n   Recommendations:")
            for recommendation in analysis['recommendations']:
                print(f"      üí° {recommendation}")

    except Exception as e:
        print(f"   ‚ö†Ô∏è  Monitoring not available in this demo: {e}")

    # 5. Database optimization strategies
    print("\\nüóÑÔ∏è  5. Database Optimization Strategies")

    print("   Available Database Indexes:")
    from bento.persistence.outbox.record import OutboxRecord
    table = OutboxRecord.__table__
    performance_indexes = [
        idx.name for idx in table.indexes
        if any(keyword in idx.name for keyword in ['cleanup', 'query_opt', 'tenant', 'processing'])
    ]

    for idx in performance_indexes:
        print(f"      - {idx}")

    print("\\n   Index Usage Recommendations:")
    print("      - ix_outbox_cleanup: Use for historical data cleanup")
    print("      - ix_outbox_query_opt: Optimizes main projector queries")
    print("      - ix_outbox_tenant_created: Multi-tenant performance")
    print("      - ix_outbox_processing_tenant: Concurrent projector efficiency")

    # 6. Historical data cleanup
    print("\\nüßπ 6. Historical Data Cleanup")

    try:
        # Simulate cleanup (dry run)
        cleanup_stats = await cleanup_old_outbox_records(
            session_factory,
            retention_days=7,      # Keep last 7 days
            batch_size=1000,       # Delete in batches of 1000
            dry_run=True          # Safe preview mode
        )

        print("   Cleanup Analysis (Dry Run):")
        print(f"      - Records eligible for cleanup: {cleanup_stats['total_candidates']}")
        print(f"      - Estimated cleanup time: {cleanup_stats['total_candidates'] // 1000 + 1} batches")
        print("      - To execute: Set dry_run=False")

    except Exception as e:
        print(f"   ‚ö†Ô∏è  Cleanup simulation not available: {e}")

    # 7. Performance tuning recommendations
    print("\\nüéØ 7. Performance Tuning Recommendations")

    recommendations = [
        "üìä Monitor connection pool usage and adjust pool_size based on concurrent load",
        "‚ö° Increase batch_size for higher throughput (trade-off: higher memory usage)",
        "üîÑ Tune sleep_busy based on event arrival patterns (lower = more responsive)",
        "üóÑÔ∏è  Run cleanup_old_outbox_records regularly to prevent table bloat",
        "üìà Use performance metrics to identify and resolve bottlenecks proactively",
        "üèóÔ∏è  Consider read replicas for high-read workloads",
        "üíæ Monitor database disk I/O and consider SSD for better performance"
    ]

    for i, rec in enumerate(recommendations, 1):
        print(f"   {i}. {rec}")

    # 8. Production deployment checklist
    print("\\nüöÄ 8. Production Deployment Checklist")

    checklist = [
        ("‚úÖ", "Database indexes created and optimized"),
        ("‚úÖ", "Connection pool sized for expected load"),
        ("‚úÖ", "Performance monitoring enabled"),
        ("‚úÖ", "Historical cleanup scheduled"),
        ("‚ö†Ô∏è", "Load testing completed (recommended)"),
        ("‚ö†Ô∏è", "Monitoring dashboards configured (recommended)"),
        ("‚ö†Ô∏è", "Alerting thresholds set (recommended)")
    ]

    for status, item in checklist:
        print(f"   {status} {item}")

    print("\\n" + "=" * 40)
    print("üéâ Performance optimization demo completed!")
    print("\\nüí° Key Takeaways:")
    print("   - Use proper indexing for 20-50% query performance improvement")
    print("   - Monitor performance metrics to detect bottlenecks early")
    print("   - Regular cleanup prevents database bloat and maintains speed")
    print("   - Tune configuration based on your specific workload patterns")

    # Cleanup
    await message_bus.stop()
    await engine.dispose()


if __name__ == "__main__":
    asyncio.run(performance_optimization_demo())
